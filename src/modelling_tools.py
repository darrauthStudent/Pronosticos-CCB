import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.stats.stattools import jarque_bera
from statsmodels.stats.diagnostic import acorr_ljungbox, het_breuschpagan
from statsmodels.stats.stattools import durbin_watson
from statsmodels.tools.tools import add_constant



def compile_models_output(fitted_values):
    """
    Reorganiza la informaci贸n de fitted_values en un diccionario estructurado por modelo.
    
    Parameters:
    -----------
    fitted_values : pd.DataFrame
        DataFrame con los valores ajustados de m煤ltiples modelos, incluyendo intervalos de confianza.
        
    Returns:
    --------
    dict
        Diccionario donde cada llave es el nombre del modelo y cada valor es un DataFrame
        con las columnas: unique_id, ds, fitted, lo_95, lo_90, hi_90, hi_95
    """
    result_dict = {}
    
    # Obtener columnas base
    base_cols = ['unique_id', 'ds', 'y']
    model_cols = [col for col in fitted_values.columns if col not in base_cols]
    
    # Identificar modelos 煤nicos
    models = set()
    for col in model_cols:
        model_name = col.split('-')[0]
        models.add(model_name)
    
    # Para cada modelo, extraer sus columnas
    for model in models:
        model_data = fitted_values[base_cols].copy()
        
        # Buscar las columnas del modelo
        fitted_col = model
        lo_95_col = f"{model}-lo-95"
        lo_90_col = f"{model}-lo-90"
        hi_90_col = f"{model}-hi-90"
        hi_95_col = f"{model}-hi-95"
        
        # Verificar que todas las columnas existan
        if all(col in fitted_values.columns for col in [fitted_col, lo_95_col, lo_90_col, hi_90_col, hi_95_col]):
            model_data['fitted'] = fitted_values[fitted_col]
            model_data['lo_95'] = fitted_values[lo_95_col]
            model_data['lo_90'] = fitted_values[lo_90_col]
            model_data['hi_90'] = fitted_values[hi_90_col]
            model_data['hi_95'] = fitted_values[hi_95_col]
            
            result_dict[model] = model_data
    
    return result_dict


def evaluate_models_metrics(models_dict):
    """
    Eval煤a m煤ltiples modelos usando m茅tricas RMSE, MAE y MAPE.
    
    Parameters:
    -----------
    models_dict : dict
        Diccionario con los resultados de compile_models_output()
        
    Returns:
    --------
    pd.DataFrame
        DataFrame con las m茅tricas de evaluaci贸n para cada modelo
    """

        
    def rmse(y_true, y_pred):
        """Root Mean Square Error"""
        return np.sqrt(np.mean((y_true - y_pred) ** 2))


    def mae(y_true, y_pred):
        """Mean Absolute Error"""
        return np.mean(np.abs(y_true - y_pred))


    def mape(y_true, y_pred):
        """Mean Absolute Percentage Error"""
        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    results = []
    
    for model_name, model_data in models_dict.items():
        y_true = model_data['y'].values
        y_pred = model_data['fitted'].values
        
        # Calcular m茅tricas usando nuestras funciones personalizadas
        rmse_val = rmse(y_true, y_pred)
        mae_val = mae(y_true, y_pred)
        mape_val = mape(y_true, y_pred)
        
        results.append({
            'model': model_name,
            'rmse': rmse_val,
            'mae': mae_val,
            'mape': mape_val
        })
    
    # Crear DataFrame y ordenar por RMSE
    metrics_df = pd.DataFrame(results)
    metrics_df = metrics_df.sort_values('rmse').reset_index(drop=True)
    
    return metrics_df



def build_X_future_step(df_y, h=12, freq='M', exog_values=None):
    """
    Construye el DataFrame de variables ex贸genas para per铆odos futuros.
    
    Parameters:
    -----------
    df_y : pd.DataFrame
        DataFrame original con columnas 'unique_id', 'ds', 'y' y variables ex贸genas
    h : int, default=12
        Horizonte de pron贸stico (n煤mero de per铆odos futuros)
    freq : str, default='M'
        Frecuencia de las fechas ('M' para mensual, 'D' para diario, etc.)
    exog_values : dict, optional
        Diccionario con valores espec铆ficos para cada variable ex贸gena.
        Si no se proporciona, usa el 煤ltimo valor observado de cada variable ex贸gena.
        
    Returns:
    --------
    pd.DataFrame
        DataFrame con variables ex贸genas para per铆odos futuros
    """
    # Identificar columnas ex贸genas (todas excepto unique_id, ds, y)
    base_cols = ['unique_id', 'ds', 'y']
    exog_cols = [col for col in df_y.columns if col not in base_cols]
    
    blocks = []
    for uid, g in df_y.groupby('unique_id'):
        last_ds = g['ds'].max()
        future_ds = pd.date_range(last_ds, periods=h+1, freq=freq)[1:]  # pr贸ximas h fechas
        
        # Crear DataFrame base para el futuro
        future_data = {
            'unique_id': uid,
            'ds': future_ds,
        }
        
        # Agregar valores para cada variable ex贸gena
        for exog_col in exog_cols:
            if exog_values and exog_col in exog_values:
                # Usar valor espec铆fico proporcionado
                future_data[exog_col] = exog_values[exog_col]
            else:
                # Usar el 煤ltimo valor observado
                last_value = g[exog_col].iloc[-1]
                future_data[exog_col] = last_value
        
        blocks.append(pd.DataFrame(future_data))
    
    return pd.concat(blocks, ignore_index=True)


def plot_ets_decomposition(original_data, fitted_model, title="ETS Decomposition", 
                          y_label="Series", figsize=(12, 16)):
    """
    Crea un gr谩fico de descomposici贸n para modelos ETS con 5 subplots:
    serie original, tendencia, pendiente, estaci贸n y residuales.
    
    Parameters:
    -----------
    original_data : array-like
        Los valores originales de la serie temporal
    fitted_model : dict
        El modelo ajustado que contiene 'states' y 'residuals'
    title : str, default="ETS Decomposition"
        T铆tulo principal del gr谩fico
    y_label : str, default="Series"
        Etiqueta para el eje Y del primer subplot
    figsize : tuple, default=(12, 16)
        Tama帽o de la figura (ancho, alto)
        
    Returns:
    --------
    fig, axes
        La figura y los ejes de matplotlib para personalizaci贸n adicional
    """
    # Crear figura con subplots en una columna
    fig, axes = plt.subplots(5, 1, figsize=figsize, sharex=True)
    
    # 1. Serie original
    axes[0].plot(original_data)
    axes[0].set_title(title)
    axes[0].set_ylabel(y_label)
    axes[0].grid(True, alpha=0.3)
    
    # 2. Tendencia (primer componente del estado)
    axes[1].plot(fitted_model["states"][:, 0])
    axes[1].set_ylabel("Tendencia")
    axes[1].grid(True, alpha=0.3)
    
    # 3. Pendiente (segundo componente del estado)
    axes[2].plot(fitted_model["states"][:, 1])
    axes[2].set_ylabel("Pendiente")
    axes[2].grid(True, alpha=0.3)
    
    # 4. Componente estacional (tercer componente del estado)
    axes[3].plot(fitted_model["states"][:, 2])
    axes[3].set_ylabel("Estaci贸n")
    axes[3].grid(True, alpha=0.3)
    
    # 5. Residuales
    axes[4].plot(fitted_model["residuals"])
    axes[4].set_ylabel("Residual")
    axes[4].set_xlabel("Tiempo")
    axes[4].grid(True, alpha=0.3)
    axes[4].axhline(y=0, color='red', linestyle='--', alpha=0.5)
    
    plt.tight_layout()
    return fig, axes


def plot_residual_analysis(residuals, fitted_values=None, title="An谩lisis de Residuales", 
                          figsize=(15, 12), bins=15, lags=20):
    """
    Crea un an谩lisis gr谩fico completo de residuales con 4 subplots:
    histograma con curva normal, Q-Q plot, scatter de valores ajustados vs residuales,
    y autocorrelaci贸n de residuales.
    
    Parameters:
    -----------
    residuals : array-like
        Los residuales del modelo
    fitted_values : array-like, optional
        Los valores ajustados del modelo. Si no se proporciona, se usa el 铆ndice
    title : str, default="An谩lisis de Residuales"
        T铆tulo principal para el an谩lisis
    figsize : tuple, default=(15, 12)
        Tama帽o de la figura (ancho, alto)
    bins : int, default=15
        N煤mero de bins para el histograma
    lags : int, default=20
        N煤mero de lags para el gr谩fico de autocorrelaci贸n
        
    Returns:
    --------
    fig, axes
        La figura y los ejes de matplotlib para personalizaci贸n adicional
    """
    # Crear figura con subplots 2x2
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    
    # 1. Histograma con curva normal
    axes[0,0].hist(residuals, bins=bins, density=True, alpha=0.7, 
                   color='skyblue', edgecolor='black')
    mu, sigma = stats.norm.fit(residuals)
    x = np.linspace(residuals.min(), residuals.max(), 100)
    axes[0,0].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, 
                   label=f'Normal(渭={mu:.4f}, ={sigma:.4f})')
    axes[0,0].set_title('Histograma de Residuales con Curva Normal')
    axes[0,0].set_xlabel('Residuales')
    axes[0,0].set_ylabel('Densidad')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)

    # 2. Q-Q Plot
    stats.probplot(residuals, dist="norm", plot=axes[0,1])
    axes[0,1].set_title('Q-Q Plot (Normalidad)')
    axes[0,1].grid(True, alpha=0.3)

    # 3. Fitted vs Residuals
    if fitted_values is not None:
        x_vals = fitted_values
        x_label = 'Valores Ajustados'
    else:
        x_vals = range(len(residuals))
        x_label = 'ndice'
    
    axes[1,0].scatter(x_vals, residuals, alpha=0.6, s=30)
    axes[1,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)
    axes[1,0].set_title('Valores Ajustados vs Residuales')
    axes[1,0].set_xlabel(x_label)
    axes[1,0].set_ylabel('Residuales')
    axes[1,0].grid(True, alpha=0.3)

    # 4. Autocorrelaci贸n de residuales
    plot_acf(residuals, lags=lags, ax=axes[1,1], alpha=0.05)
    axes[1,1].set_title('Autocorrelaci贸n de Residuales')
    axes[1,1].grid(True, alpha=0.3)

    plt.suptitle(title, fontsize=16, y=1.02)
    plt.tight_layout()
    return fig, axes


def perform_residual_tests(residuals, title="Pruebas Estad铆sticas de Residuales", alpha=0.05):
    """
    Realiza un conjunto completo de pruebas estad铆sticas sobre los residuales de un modelo.
    Incluye pruebas de normalidad, autocorrelaci贸n y homocedasticidad.
    
    Parameters:
    -----------
    residuals : array-like
        Los residuales del modelo a analizar
    title : str, default="Pruebas Estad铆sticas de Residuales"
        T铆tulo para el reporte de pruebas
    alpha : float, default=0.05
        Nivel de significancia para las pruebas estad铆sticas
        
    Returns:
    --------
    dict
        Diccionario con todos los resultados de las pruebas estad铆sticas
    """
    results = {}
    
    # Convertir a pandas Series para evitar problemas
    residuals_series = pd.Series(residuals)
    
    print(title.upper())
    print("=" * len(title))
    print()
    
    # ========================================
    # 1. PRUEBAS DE NORMALIDAD
    # ========================================
    print("1. PRUEBAS DE NORMALIDAD:")
    print("-" * 30)
    
    # Shapiro-Wilk Test
    try:
        shapiro_stat, shapiro_p = stats.shapiro(residuals_series)
        results['shapiro'] = {'statistic': shapiro_stat, 'p_value': shapiro_p}
        print(f"Shapiro-Wilk Test:")
        print(f"   Estad铆stico: {shapiro_stat:.6f}")
        print(f"   p-valor: {shapiro_p:.6f}")
        print(f"   Conclusi贸n: {'Residuales NO siguen distribuci贸n normal' if shapiro_p < alpha else 'No se rechaza normalidad'}")
        print()
    except Exception as e:
        print(f"Error en Shapiro-Wilk Test: {e}")
        results['shapiro'] = {'error': str(e)}
    
    # Jarque-Bera Test
    try:
        jb_stat, jb_p, skew, kurtosis = jarque_bera(residuals)
        results['jarque_bera'] = {
            'statistic': jb_stat, 
            'p_value': jb_p, 
            'skewness': skew, 
            'kurtosis': kurtosis
        }
        print(f"Jarque-Bera Test:")
        print(f"   Estad铆stico: {jb_stat:.6f}")
        print(f"   p-valor: {jb_p:.6f}")
        print(f"   Sesgo: {skew:.6f}")
        print(f"   Curtosis: {kurtosis:.6f}")
        print(f"   Conclusi贸n: {'Residuales NO siguen distribuci贸n normal' if jb_p < alpha else 'No se rechaza normalidad'}")
        print()
    except Exception as e:
        print(f"Error en Jarque-Bera Test: {e}")
        results['jarque_bera'] = {'error': str(e)}
    
    # Anderson-Darling Test
    try:
        ad_stat, ad_critical, ad_significance = stats.anderson(residuals_series, dist='norm')
        results['anderson_darling'] = {
            'statistic': ad_stat, 
            'critical_values': ad_critical, 
            'significance_levels': ad_significance
        }
        print(f"Anderson-Darling Test:")
        print(f"   Estad铆stico: {ad_stat:.6f}")
        print(f"   Valor cr铆tico (5%): {ad_critical[2]:.6f}")
        print(f"   Conclusi贸n: {'Residuales NO siguen distribuci贸n normal' if ad_stat > ad_critical[2] else 'No se rechaza normalidad'}")
        print()
    except Exception as e:
        print(f"Error en Anderson-Darling Test: {e}")
        results['anderson_darling'] = {'error': str(e)}
    
    print()
    
    # ========================================
    # 2. PRUEBAS DE AUTOCORRELACIN
    # ========================================
    print("2. PRUEBAS DE AUTOCORRELACIN:")
    print("-" * 30)
    
    # Ljung-Box Test
    try:
        lb_result = acorr_ljungbox(residuals, lags=10, return_df=True)
        lb_stat = lb_result['lb_stat'].iloc[-1]
        lb_p = lb_result['lb_pvalue'].iloc[-1]
        results['ljung_box'] = {'statistic': lb_stat, 'p_value': lb_p}
        
        print(f"Ljung-Box Test (lag 10):")
        print(f"   Estad铆stico: {lb_stat:.6f}")
        print(f"   p-valor: {lb_p:.6f}")
        print(f"   Conclusi贸n: {'HAY autocorrelaci贸n significativa' if lb_p < alpha else 'No hay autocorrelaci贸n significativa'}")
        print()
    except Exception as e:
        try:
            # Versi贸n alternativa
            lb_result = acorr_ljungbox(residuals, lags=10, return_df=False)
            if hasattr(lb_result, '__len__') and len(lb_result) == 2:
                lb_stat, lb_p = lb_result
                results['ljung_box'] = {'statistic': lb_stat, 'p_value': lb_p}
                
                print(f"Ljung-Box Test (lag 10):")
                print(f"   Estad铆stico: {lb_stat:.6f}")
                print(f"   p-valor: {lb_p:.6f}")
                print(f"   Conclusi贸n: {'HAY autocorrelaci贸n significativa' if lb_p < alpha else 'No hay autocorrelaci贸n significativa'}")
                print()
            else:
                print(f"Error en Ljung-Box Test: formato de resultado no reconocido")
                results['ljung_box'] = {'error': 'Formato de resultado no reconocido'}
        except Exception as e2:
            print(f"Error en Ljung-Box Test: {e2}")
            results['ljung_box'] = {'error': str(e2)}
    
    # Durbin-Watson Test
    try:
        dw_stat = durbin_watson(residuals)
        results['durbin_watson'] = {'statistic': dw_stat}
        
        print(f"Durbin-Watson Test:")
        print(f"   Estad铆stico: {dw_stat:.6f}")
        if dw_stat < 1.5:
            interpretation = 'Autocorrelaci贸n positiva'
        elif dw_stat > 2.5:
            interpretation = 'Autocorrelaci贸n negativa'
        else:
            interpretation = 'Sin autocorrelaci贸n fuerte'
        print(f"   Interpretaci贸n: {interpretation}")
        print()
    except Exception as e:
        print(f"Error en Durbin-Watson Test: {e}")
        results['durbin_watson'] = {'error': str(e)}
    
    print()
    
    # ========================================
    # 3. PRUEBAS DE HOMOCEDASTICIDAD
    # ========================================
    print("3. PRUEBAS DE HOMOCEDASTICIDAD:")
    print("-" * 30)
    
    # Breusch-Pagan Test
    try:
        X = np.arange(len(residuals)).reshape(-1, 1)
        X_with_const = add_constant(X)
        bp_lm, bp_p, bp_fvalue, bp_f_p = het_breuschpagan(residuals, X_with_const)
        results['breusch_pagan'] = {
            'lm_statistic': bp_lm, 
            'lm_p_value': bp_p, 
            'f_statistic': bp_fvalue, 
            'f_p_value': bp_f_p
        }
        
        print(f"Breusch-Pagan Test:")
        print(f"   Estad铆stico LM: {bp_lm:.6f}")
        print(f"   p-valor: {bp_p:.6f}")
        print(f"   Estad铆stico F: {bp_fvalue:.6f}")
        print(f"   p-valor F: {bp_f_p:.6f}")
        print(f"   Conclusi贸n: {'HAY heterocedasticidad' if bp_p < alpha else 'No hay heterocedasticidad (homocedasticidad)'}")
        print()
    except Exception as e:
        print(f"Error en Breusch-Pagan Test: {e}")
        results['breusch_pagan'] = {'error': str(e)}
    
    # Levene Test
    try:
        mid = len(residuals) // 2
        group1 = residuals[:mid]
        group2 = residuals[mid:]
        levene_stat, levene_p = stats.levene(group1, group2)
        results['levene'] = {'statistic': levene_stat, 'p_value': levene_p}
        
        print(f"Levene Test (varianzas iguales entre grupos):")
        print(f"   Estad铆stico: {levene_stat:.6f}")
        print(f"   p-valor: {levene_p:.6f}")
        print(f"   Conclusi贸n: {'Varianzas NO son iguales (heterocedasticidad)' if levene_p < alpha else 'Varianzas son iguales (homocedasticidad)'}")
        print()
    except Exception as e:
        print(f"Error en Levene Test: {e}")
        results['levene'] = {'error': str(e)}
    
    return results


def forecast_with_corrected_dates(sf_model, df, h, level=None, fitted=True, X_df=None, freq='M'):
    """
    Wrapper para sf.forecast que corrige las fechas de pron贸stico moviendo una fecha hacia adelante.
    
    Esta funci贸n soluciona el problema com煤n donde StatsForecast repite la 煤ltima fecha observada
    en lugar de generar fechas futuras correctas.
    
    Parameters:
    -----------
    sf_model : StatsForecast
        El modelo StatsForecast ajustado
    df : pd.DataFrame
        El DataFrame con los datos hist贸ricos
    h : int
        Horizonte de pron贸stico (n煤mero de per铆odos futuros)
    level : list, optional
        Niveles de confianza para intervalos (ej. [90, 95])
    fitted : bool, default=True
        Si incluir valores ajustados
    X_df : pd.DataFrame, optional
        DataFrame con variables ex贸genas para pron贸sticos futuros
    freq : str, default='M'
        Frecuencia de las fechas ('M' para mensual, 'D' para diario, etc.)
        
    Returns:
    --------
    pd.DataFrame
        DataFrame de pron贸sticos con fechas corregidas
    """
    # Generar pron贸stico usando StatsForecast
    forecast_result = sf_model.forecast(
        df=df, 
        h=h, 
        level=level, 
        fitted=fitted, 
        X_df=X_df
    )
    
    # Corregir las fechas para cada unique_id
    corrected_forecast = forecast_result.copy()
    
    for unique_id in forecast_result['unique_id'].unique():
        # Filtrar datos para este unique_id
        mask = corrected_forecast['unique_id'] == unique_id
        forecast_subset = corrected_forecast[mask].copy()
        
        # Obtener la 煤ltima fecha del DataFrame original para este unique_id
        historical_data = df[df['unique_id'] == unique_id]
        last_date = historical_data['ds'].max()
        
        # Generar las fechas correctas (h per铆odos hacia adelante)
        future_dates = pd.date_range(
            start=last_date, 
            periods=h + 1, 
            freq=freq
        )[1:]  # Excluir la fecha inicial (煤ltima observada)
        
        # Actualizar las fechas en el resultado
        corrected_forecast.loc[mask, 'ds'] = future_dates
    
    return corrected_forecast


def create_hybrid_forecast(ets_forecast, sarimax_forecast, target_year=2026, target_month=3,
                          ets_main_col='MMM', sarimax_main_col='auto', hybrid_alias='ESM',
                          show_comparison=True):
    """
    Crea un pron贸stico h铆brido combinando ETS y SARIMAX para meses espec铆ficos.
    
    Parameters:
    -----------
    ets_forecast : pd.DataFrame
        DataFrame con pron贸sticos ETS
    sarimax_forecast : pd.DataFrame
        DataFrame con pron贸sticos SARIMAX
    target_year : int, default=2026
        A帽o objetivo para reemplazar con SARIMAX
    target_month : int, default=3
        Mes objetivo para reemplazar con SARIMAX (3 = marzo)
    ets_main_col : str, default='MMM'
        Nombre de la columna principal en ets_forecast
    sarimax_main_col : str, default='auto'
        Nombre de la columna principal en sarimax_forecast
    hybrid_alias : str, default='ESM'
        Alias para el modelo h铆brido en las columnas de salida
    show_comparison : bool, default=True
        Si mostrar comparaci贸n de valores para el mes objetivo
        
    Returns:
    --------
    pd.DataFrame
        DataFrame con pron贸sticos h铆bridos
    """
    # Preparar tabla base con pron贸sticos ETS
    hybrid_forecast = ets_forecast.copy()
    
    # Crear mapeo de columnas din谩mico
    column_mapping = {}
    for col in ets_forecast.columns:
        if col == 'ds' or col == 'unique_id':
            continue
        if col == ets_main_col:
            column_mapping[col] = hybrid_alias
        elif col.startswith(f"{ets_main_col}-"):
            new_col = col.replace(ets_main_col, hybrid_alias)
            column_mapping[col] = new_col
    
    # Renombrar columnas
    hybrid_forecast = hybrid_forecast.rename(columns=column_mapping)
    
    # Identificar el mes/a帽o objetivo para reemplazar
    target_mask = (hybrid_forecast['ds'].dt.year == target_year) & (hybrid_forecast['ds'].dt.month == target_month)
    
    if target_mask.any():
        # Obtener el valor de SARIMAX para el per铆odo objetivo
        target_sarimax = sarimax_forecast[
            (sarimax_forecast['ds'].dt.year == target_year) & 
            (sarimax_forecast['ds'].dt.month == target_month)
        ]
        
        if len(target_sarimax) > 0:
            # Crear mapeo para columnas SARIMAX
            sarimax_mapping = {}
            for col in sarimax_forecast.columns:
                if col == 'ds' or col == 'unique_id':
                    continue
                if col == sarimax_main_col:
                    sarimax_mapping[col] = hybrid_alias
                elif col.startswith(f"{sarimax_main_col}-"):
                    new_col = col.replace(sarimax_main_col, hybrid_alias)
                    sarimax_mapping[col] = new_col
            
            # Reemplazar valores del per铆odo objetivo con los del modelo SARIMAX
            for sarimax_col, hybrid_col in sarimax_mapping.items():
                if hybrid_col in hybrid_forecast.columns:
                    hybrid_forecast.loc[target_mask, hybrid_col] = target_sarimax[sarimax_col].iloc[0]
            
        else:
            print(f"No se encontr贸 {target_year}-{target_month:02d} en sarimax_forecast")
    else:
        print(f"No se encontr贸 {target_year}-{target_month:02d} en hybrid_forecast")
    
    # Mostrar comparaci贸n si se solicita
    if show_comparison:
        print(f"COMPARACIN DE PRONSTICOS PARA {target_year}-{target_month:02d}")
        print("-" * 45)
        
        # Filtrar el per铆odo objetivo de cada tabla
        target_ets = ets_forecast[target_mask][['ds', ets_main_col]].copy() if target_mask.any() else pd.DataFrame()
        target_sarimax_comp = sarimax_forecast[
            (sarimax_forecast['ds'].dt.year == target_year) & 
            (sarimax_forecast['ds'].dt.month == target_month)
        ][['ds', sarimax_main_col]].copy()
        target_hybrid = hybrid_forecast[target_mask][['ds', hybrid_alias]].copy() if target_mask.any() else pd.DataFrame()
        
        if len(target_ets) > 0:
            print(f"ETS (Original):     {target_ets[ets_main_col].iloc[0]:,.2f}")
        if len(target_sarimax_comp) > 0:
            print(f"SARIMAX:           {target_sarimax_comp[sarimax_main_col].iloc[0]:,.2f}")
        if len(target_hybrid) > 0:
            print(f"{hybrid_alias} (Final):       {target_hybrid[hybrid_alias].iloc[0]:,.2f}")
    
    return hybrid_forecast


def plot_forecast_with_intervals(historical_data, forecast_data, 
                                main_col='ESM', ds_col='ds', y_col='y',
                                title="Pron贸stico de Series Temporales",
                                y_label="Valores", figsize=(14, 8),
                                highlight_periods=None):
    """
    Crea un gr谩fico profesional de serie temporal con pron贸sticos e intervalos de confianza.
    
    Parameters:
    -----------
    historical_data : pd.DataFrame
        DataFrame con datos hist贸ricos (debe tener columnas ds_col y y_col)
    forecast_data : pd.DataFrame
        DataFrame con pron贸sticos (debe tener main_col y columnas de intervalos)
    main_col : str, default='ESM'
        Nombre de la columna principal del pron贸stico
    ds_col : str, default='ds'
        Nombre de la columna de fechas
    y_col : str, default='y'
        Nombre de la columna de valores en datos hist贸ricos
    title : str, default="Pron贸stico de Series Temporales"
        T铆tulo del gr谩fico
    y_label : str, default="Valores"
        Etiqueta para el eje Y
    figsize : tuple, default=(14, 8)
        Tama帽o de la figura
    highlight_periods : list, optional
        Lista de diccionarios con per铆odos a destacar
        Formato: [{'year': 2026, 'month': 3, 'label': 'Especial', 'color': 'blue'}]
        
    Returns:
    --------
    fig, ax
        Figura y ejes de matplotlib para personalizaci贸n adicional
    """
    fig, ax = plt.subplots(figsize=figsize)
    
    # Datos hist贸ricos
    ax.plot(historical_data[ds_col], historical_data[y_col], 
            color='black', linewidth=2, label='Datos Hist贸ricos', 
            marker='o', markersize=4, alpha=0.8)
    
    # Pron贸stico principal
    ax.plot(forecast_data[ds_col], forecast_data[main_col], 
            color='red', linewidth=3, label=f'Pron贸stico ({main_col})', 
            marker='s', markersize=6)
    
    # Intervalos de confianza (si existen)
    ic_95_lo = f"{main_col}-lo-95"
    ic_95_hi = f"{main_col}-hi-95"
    ic_90_lo = f"{main_col}-lo-90"
    ic_90_hi = f"{main_col}-hi-90"
    
    if ic_95_lo in forecast_data.columns and ic_95_hi in forecast_data.columns:
        ax.fill_between(forecast_data[ds_col], 
                       forecast_data[ic_95_lo], 
                       forecast_data[ic_95_hi], 
                       alpha=0.2, color='red', label='IC 95%')
    
    if ic_90_lo in forecast_data.columns and ic_90_hi in forecast_data.columns:
        ax.fill_between(forecast_data[ds_col], 
                       forecast_data[ic_90_lo], 
                       forecast_data[ic_90_hi], 
                       alpha=0.3, color='red', label='IC 90%')
    
    # Destacar per铆odos espec铆ficos si se proporcionan
    if highlight_periods:
        for period in highlight_periods:
            year = period.get('year')
            month = period.get('month')
            label = period.get('label', f'{year}-{month:02d}')
            color = period.get('color', 'blue')
            marker = period.get('marker', '*')
            size = period.get('size', 150)
            
            # Filtrar el per铆odo espec铆fico del pron贸stico
            period_mask = (forecast_data[ds_col].dt.year == year) & (forecast_data[ds_col].dt.month == month)
            period_data = forecast_data[period_mask]
            
            if len(period_data) > 0:
                ax.scatter(period_data[ds_col], period_data[main_col], 
                          color=color, s=size, marker=marker, zorder=5, 
                          label=label, edgecolors='white', linewidth=2)
    
    # Configuraci贸n del gr谩fico
    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
    ax.set_xlabel('Fecha', fontsize=12)
    ax.set_ylabel(y_label, fontsize=12)
    ax.legend(loc='upper left', fontsize=10, frameon=True, fancybox=True, shadow=True)
    ax.grid(True, alpha=0.3)
    
    # Formato de fechas en eje x
    import matplotlib.dates as mdates
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    
    # Mejorar el aspecto general
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_linewidth(0.5)
    ax.spines['bottom'].set_linewidth(0.5)
    
    plt.tight_layout()
    return fig, ax


def calculate_annual_variation(historical_data, forecast_data, 
                             base_year=2025, target_year=2026,
                             date_col='ds', value_col='y', 
                             forecast_col='ESM', currency='COP',
                             show_results=True):
    """
    Calcula la variaci贸n porcentual anual entre dos a帽os consecutivos.
    
    Parameters:
    -----------
    historical_data : pd.DataFrame
        DataFrame con datos hist贸ricos
    forecast_data : pd.DataFrame  
        DataFrame con datos de pron贸stico
    base_year : int, default=2025
        A帽o base para la comparaci贸n
    target_year : int, default=2026
        A帽o objetivo para calcular la variaci贸n
    date_col : str, default='ds'
        Nombre de la columna de fechas
    value_col : str, default='y'
        Nombre de la columna de valores en datos hist贸ricos
    forecast_col : str, default='ESM'
        Nombre de la columna de pron贸stico
    currency : str, default='COP'
        Moneda para mostrar en los resultados
    show_results : bool, default=True
        Si mostrar los resultados formateados
        
    Returns:
    --------
    dict
        Diccionario con los resultados del c谩lculo:
        - 'total_base_year': Total del a帽o base
        - 'total_target_year': Total del a帽o objetivo
        - 'absolute_variation': Variaci贸n absoluta
        - 'percentage_variation': Variaci贸n porcentual
        - 'base_year': A帽o base
        - 'target_year': A帽o objetivo
    """
    import pandas as pd
    
    # Preparar forecast_data con columna year si no existe
    if 'year' not in forecast_data.columns:
        forecast_data = forecast_data.copy()
        forecast_data['year'] = forecast_data[date_col].dt.year
    
    # Obtener datos del a帽o base
    base_data = historical_data[historical_data[date_col].dt.year == base_year]
    total_base = base_data[value_col].sum()
    
    # Obtener pron贸sticos del a帽o objetivo (primeros 12 meses)
    target_data = forecast_data[forecast_data['year'] == target_year].head(12)
    total_target = target_data[forecast_col].sum()
    
    # Calcular variaci贸n
    absolute_variation = total_target - total_base
    percentage_variation = (absolute_variation / total_base) * 100
    
    # Crear resultado
    results = {
        'total_base_year': total_base,
        'total_target_year': total_target,
        'absolute_variation': absolute_variation,
        'percentage_variation': percentage_variation,
        'base_year': base_year,
        'target_year': target_year
    }
    
    # Mostrar resultados formateados si se solicita
    if show_results:
        print(f" VARIACIN PORCENTUAL ANUAL ESPERADA PARA {target_year}")
        print("=" * 60)
        print(f"Total {base_year} (Real):        ${total_base:,.0f} millones {currency}")
        print(f"Total {target_year} (Pron贸stico):  ${total_target:,.0f} millones {currency}")
        print(f"Variaci贸n Absoluta:       ${absolute_variation:+,.0f} millones {currency}")
        print(f"VARIACIN PORCENTUAL:     {percentage_variation:+.2f}%")
        print("=" * 60)
    
    return results


def plot_annual_comparison(results_dict, figsize=(10, 6), currency='COP'):
    """
    Crea un gr谩fico de barras comparativo entre dos a帽os usando los resultados
    de la funci贸n calculate_annual_variation.
    
    Parameters:
    -----------
    results_dict : dict
        Diccionario con resultados de calculate_annual_variation
    figsize : tuple, default=(10, 6)
        Tama帽o de la figura (ancho, alto)
    currency : str, default='COP'
        Moneda para mostrar en las etiquetas
        
    Returns:
    --------
    fig, ax
        Figura y ejes de matplotlib para personalizaci贸n adicional
    """
    import matplotlib.pyplot as plt
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Datos para el gr谩fico usando los resultados
    a帽os = [f"{results_dict['base_year']} (Real)", f"{results_dict['target_year']} (Pron贸stico)"]
    valores = [results_dict['total_base_year'], results_dict['total_target_year']]
    colores = ['steelblue', 'orange']
    
    # Crear gr谩fico de barras
    bars = ax.bar(a帽os, valores, color=colores, alpha=0.8, width=0.6)
    
    # Personalizar el gr谩fico
    ax.set_ylabel(f'Ingresos (Millones {currency})')
    ax.set_title(f'Comparaci贸n Anual: Ingresos {results_dict["base_year"]} vs Pron贸stico {results_dict["target_year"]}')
    ax.grid(True, alpha=0.3, axis='y')
    
    # Agregar valores sobre las barras
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                 f'${height:,.0f}M', ha='center', va='bottom', fontsize=12, fontweight='bold')
    
    # Agregar texto con la variaci贸n porcentual
    ax.text(0.5, max(valores) * 0.8, f'Variaci贸n: {results_dict["percentage_variation"]:+.2f}%', 
            transform=ax.transData, ha='center', fontsize=16, fontweight='bold',
            bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
    
    plt.tight_layout()
    
    # Interpretaci贸n simple
    if results_dict['percentage_variation'] > 0:
        interpretacion = f"Se espera un CRECIMIENTO del {results_dict['percentage_variation']:.2f}% en los ingresos para {results_dict['target_year']}"
    else:
        interpretacion = f"Se espera una DISMINUCIN del {abs(results_dict['percentage_variation']):.2f}% en los ingresos para {results_dict['target_year']}"
    
    print(f" CONCLUSIN: {interpretacion}")
    
    return fig, ax


def export_data(data, filename, output_dir='data/model_outputs', 
                file_format='csv', add_timestamp=False):
    """
    Exporta un DataFrame a un archivo en el directorio especificado.
    
    Parameters:
    -----------
    data : pd.DataFrame
        DataFrame a exportar
    filename : str
        Nombre del archivo (sin extensi贸n)
    output_dir : str, default='data/model_outputs'
        Directorio de salida relativo al directorio ra铆z del proyecto
    file_format : str, default='csv'
        Formato del archivo ('csv', 'excel', 'parquet')
    add_timestamp : bool, default=False
        Si agregar timestamp al nombre del archivo
        
    Returns:
    --------
    str
        Ruta completa del archivo guardado
    """
    import pandas as pd
    import os
    from datetime import datetime
    
    # Crear directorio si no existe
    os.makedirs(output_dir, exist_ok=True)
    
    # Agregar timestamp si se solicita
    if add_timestamp:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename}_{timestamp}"
    
    # Determinar extensi贸n y m茅todo de guardado
    if file_format.lower() == 'csv':
        file_path = os.path.join(output_dir, f"{filename}.csv")
        data.to_csv(file_path, index=False)
    elif file_format.lower() in ['excel', 'xlsx']:
        file_path = os.path.join(output_dir, f"{filename}.xlsx")
        data.to_excel(file_path, index=False)
    elif file_format.lower() == 'parquet':
        file_path = os.path.join(output_dir, f"{filename}.parquet")
        data.to_parquet(file_path, index=False)
    else:
        raise ValueError(f"Formato no soportado: {file_format}")
    
    # Obtener informaci贸n del archivo
    file_size = os.path.getsize(file_path)
    file_size_mb = file_size / (1024 * 1024)
    
    print(f" DATOS EXPORTADOS EXITOSAMENTE")
    print("=" * 50)
    print(f"Archivo:     {os.path.basename(file_path)}")
    print(f"Directorio:  {output_dir}")
    print(f"Ruta:        {file_path}")
    print(f"Formato:     {file_format.upper()}")
    print(f"Tama帽o:      {file_size_mb:.2f} MB")
    print(f"Filas:       {len(data):,}")
    print(f"Columnas:    {len(data.columns)}")
    print(f"Fecha:       {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    return file_path